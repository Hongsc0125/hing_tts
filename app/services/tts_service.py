import os
import sys
import tempfile
import torch
import random
import numpy as np
from pathlib import Path
import soundfile as sf
from typing import List, Optional
import traceback

# VibeVoice ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
vibevoice_path = "/home/hsc0125/Hing_tts/models"
if vibevoice_path not in sys.path:
    sys.path.insert(0, vibevoice_path)

try:
    from VibeVoice.vibevoice.modular.modeling_vibevoice_inference import VibeVoiceForConditionalGenerationInference
    from VibeVoice.vibevoice.processor.vibevoice_processor import VibeVoiceProcessor
    from VibeVoice.vibevoice.modular.configuration_vibevoice import VibeVoiceConfig
    VIBEVOICE_AVAILABLE = True
    print("âœ… VibeVoice ë¡œì»¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    print(f"âŒ VibeVoice ë¡œì»¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
    VIBEVOICE_AVAILABLE = False


class TTSService:
    def __init__(self):
        self.model_path = "/home/hsc0125/Hing_tts/models/VibeVoice-1.5B"
        self.audio_samples_path = "/home/hsc0125/Hing_tts/models/audio_data"
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.model = None
        self.processor = None
        self.korean_voices = {}
        print(f"ğŸ™ï¸ VibeVoice TTS ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì¤‘... ë””ë°”ì´ìŠ¤: {self.device}")
        self._initialize_model()
        self._load_korean_voices()
    
    def _initialize_model(self):
        """VibeVoice ëª¨ë¸ ì´ˆê¸°í™”"""
        if not VIBEVOICE_AVAILABLE:
            raise Exception("VibeVoice ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        try:
            print(f"ğŸ“ VibeVoice ëª¨ë¸ ë¡œë”©...")
            
            # í”„ë¡œì„¸ì„œ ë¡œë“œ
            self.processor = VibeVoiceProcessor.from_pretrained(
                "microsoft/VibeVoice-1.5B",
                trust_remote_code=True
            )
            print("âœ… VibeVoice í”„ë¡œì„¸ì„œ ë¡œë“œ ì„±ê³µ")
            
            # ëª¨ë¸ ë¡œë“œ
            self.model = VibeVoiceForConditionalGenerationInference.from_pretrained(
                "microsoft/VibeVoice-1.5B",
                torch_dtype=torch.bfloat16 if self.device == "cuda" else torch.float32,
                device_map='cuda' if self.device == "cuda" else None,
                trust_remote_code=True,
                attn_implementation="eager"  # ì•ˆì •ì„±ì„ ìœ„í•´ eager ì‚¬ìš©
            )
            
            self.model.eval()
            print("âœ… VibeVoice ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
            
            # DDPM ì„¤ì • (ê³µì‹ ë°ëª¨ ê¸°ë³¸ê°’)
            if hasattr(self.model, 'set_ddmp_inference_steps'):
                self.model.set_ddmp_inference_steps(num_steps=5)
                print("âœ… DDPM ì¶”ë¡  ìŠ¤í… ì„¤ì •: 5")
            
            print("ğŸ‰ VibeVoice ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ VibeVoice ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            traceback.print_exc()
            raise e
    
    def _load_korean_voices(self):
        """í•œêµ­ì–´ ìŒì„± ìƒ˜í”Œë“¤ì„ ë¡œë“œ"""
        try:
            audio_data_path = Path(self.audio_samples_path)
            print(f"ğŸ” ì˜¤ë””ì˜¤ ê²½ë¡œ í™•ì¸: {audio_data_path}")
            
            if not audio_data_path.exists():
                print(f"âš ï¸ ì˜¤ë””ì˜¤ ìƒ˜í”Œ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.audio_samples_path}")
                # í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
                audio_data_path.mkdir(parents=True, exist_ok=True)
                print("ğŸ“ ì˜¤ë””ì˜¤ í´ë” ìƒì„±ë¨")
                return
            
            # ëª¨ë“  ì˜¤ë””ì˜¤ íŒŒì¼ í™•ì¸ (.wav, .mp3 ë“±)
            audio_files = []
            for ext in ['*.wav', '*.mp3', '*.flac', '*.ogg']:
                audio_files.extend(list(audio_data_path.glob(ext)))
            
            print(f"ğŸ” ë°œê²¬ëœ ì˜¤ë””ì˜¤ íŒŒì¼: {len(audio_files)}ê°œ")
            for f in audio_files:
                print(f"  - {f.name}")
            
            if not audio_files:
                print("âš ï¸ ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ìŒì„±ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
                return
            
            korean_speaker_names = ["í•œêµ­ì—¬ì„±1", "í•œêµ­ì—¬ì„±2", "í•œêµ­ë‚¨ì„±1", "í•œêµ­ë‚¨ì„±2", "í•œêµ­ì—¬ì„±3"]
            
            for i, audio_file in enumerate(audio_files[:len(korean_speaker_names)]):
                speaker_name = korean_speaker_names[i]
                self.korean_voices[speaker_name] = str(audio_file)
                print(f"ğŸ¤ í•œêµ­ì–´ ìŒì„± ë“±ë¡: {speaker_name} -> {audio_file.name}")
            
            # ì²« ë²ˆì§¸ íŒŒì¼ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
            if audio_files:
                self.korean_voices["default"] = str(audio_files[0])
                print(f"âœ… ê¸°ë³¸ ìŒì„± ì„¤ì •: {audio_files[0].name}")
                
        except Exception as e:
            print(f"âŒ í•œêµ­ì–´ ìŒì„± ìƒ˜í”Œ ë¡œë“œ ì‹¤íŒ¨: {e}")
            traceback.print_exc()
    
    def list_korean_voices(self) -> List[str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ í•œêµ­ì–´ ìŒì„± ëª©ë¡ ë°˜í™˜"""
        return list(self.korean_voices.keys())
    
    def generate_speech(self, text: str, speaker_names: List[str] = None, cfg_scale: float = 3.0) -> str:
        """
        VibeVoiceë¡œ í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜
        """
        if not self.model or not self.processor:
            raise Exception("VibeVoice ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
        
        # ì„ì‹œ ì¶œë ¥ íŒŒì¼ ìƒì„±
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_file:
            output_path = tmp_file.name
        
        try:
            print(f"ğŸ¬ ìŒì„± ìƒì„± ì‹œì‘: {text[:50]}...")
            
            # ê°„ë‹¨í•œ ìŠ¤í¬ë¦½íŠ¸ í¬ë§·íŒ…
            formatted_script = f"Speaker 0: {text}"
            
            # í•œêµ­ì–´ ìŒì„± ìƒ˜í”Œ ì¤€ë¹„
            voice_samples = []
            if self.korean_voices:
                if "default" in self.korean_voices:
                    voice_path = self.korean_voices["default"]
                else:
                    voice_path = list(self.korean_voices.values())[0]
                voice_samples = [voice_path]
                print(f"ğŸ¤ í•œêµ­ì–´ ìŒì„± ìƒ˜í”Œ ì‚¬ìš©: {voice_path}")
            else:
                print("âš ï¸ í•œêµ­ì–´ ìŒì„± ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ VibeVoice ìŒì„±ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            
            # VibeVoice ì²˜ë¦¬ - ìŒì„± ìƒ˜í”Œ í¬í•¨
            print(f"ğŸ”„ í…ìŠ¤íŠ¸ ì²˜ë¦¬: {formatted_script}")
            if voice_samples:
                print(f"ğŸ¤ ìŒì„± ìƒ˜í”Œ ê²½ë¡œ: {voice_samples}")
                inputs = self.processor(
                    text=[formatted_script],
                    voice_samples=[voice_samples],
                    padding=True,
                    return_tensors="pt",
                    return_attention_mask=True
                )
            else:
                # ìŒì„± ìƒ˜í”Œì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ì²˜ë¦¬
                print("âš ï¸ ìŒì„± ìƒ˜í”Œ ì—†ì´ ì²˜ë¦¬")
                inputs = self.processor(
                    text=[formatted_script],
                    padding=True,
                    return_tensors="pt",
                    return_attention_mask=True
                )
            
            print(f"ë””ë²„ê·¸ - inputs í‚¤ë“¤: {list(inputs.keys())}")
            for key, value in inputs.items():
                print(f"  {key}: type={type(value)}, is_tensor={torch.is_tensor(value) if value is not None else False}")
            
            # GPUë¡œ ì´ë™
            if self.device == "cuda":
                for key, value in inputs.items():
                    if value is not None and torch.is_tensor(value):
                        try:
                            inputs[key] = value.to(self.device)
                            print(f"  âœ… {key} GPUë¡œ ì´ë™ ì™„ë£Œ")
                        except Exception as e:
                            print(f"  âŒ {key} GPU ì´ë™ ì‹¤íŒ¨: {e}")
                    else:
                        print(f"  â­ï¸ {key} ìŠ¤í‚µ (None ë˜ëŠ” ë¹„í…ì„œ)")
            
            # ìŒì„± ìƒì„±
            print(f"ğŸµ ìŒì„± ìƒì„± ì¤‘... (CFG: {cfg_scale})")
            
            # None ê°’ë“¤ì„ í•„í„°ë§í•˜ì—¬ ì „ë‹¬
            filtered_inputs = {k: v for k, v in inputs.items() if v is not None}
            print(f"ëª¨ë¸ì— ì „ë‹¬í•  inputs: {list(filtered_inputs.keys())}")
            
            try:
                with torch.no_grad():
                    outputs = self.model.generate(
                        **filtered_inputs,
                        cfg_scale=cfg_scale,
                        tokenizer=self.processor.tokenizer
                    )
            except Exception as gen_error:
                print(f"ğŸ” ëª¨ë¸ ìƒì„± ì¤‘ ìƒì„¸ ì˜¤ë¥˜:")
                traceback.print_exc()
                raise gen_error
            
            # ì˜¤ë””ì˜¤ ì¶”ì¶œ ë° ì €ì¥
            if hasattr(outputs, 'speech_outputs') and outputs.speech_outputs:
                audio_data = outputs.speech_outputs[0]
                
                if torch.is_tensor(audio_data):
                    if audio_data.dtype == torch.bfloat16:
                        audio_data = audio_data.float()
                    audio_array = audio_data.cpu().detach().numpy()
                else:
                    audio_array = np.array(audio_data, dtype=np.float32)
                
                # ì°¨ì› ì •ë¦¬
                while audio_array.ndim > 1 and audio_array.shape[0] == 1:
                    audio_array = audio_array.squeeze(0)
                if audio_array.ndim > 1:
                    audio_array = audio_array.flatten()
                
                # ì •ê·œí™”
                max_val = max(abs(audio_array.min()), abs(audio_array.max()))
                if max_val > 1.0:
                    audio_array = audio_array / max_val * 0.95
                
                # ì €ì¥
                sf.write(output_path, audio_array, 24000)
                print(f"ğŸ’¾ ìŒì„± íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_path}")
                return output_path
            else:
                raise Exception("ìŒì„± ì¶œë ¥ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            
        except Exception as e:
            print(f"âŒ ìŒì„± ìƒì„± ì‹¤íŒ¨: {e}")
            if os.path.exists(output_path):
                os.unlink(output_path)
            raise e


# ì „ì—­ TTS ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
tts_service = TTSService()