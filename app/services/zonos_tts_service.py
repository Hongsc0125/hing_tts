import os
import sys
import tempfile
import torch
import torchaudio
import numpy as np
from pathlib import Path
import soundfile as sf
from typing import List, Optional
import traceback

# Zonos ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
zonos_path = "/home/hsc0125/Hing_tts/models/Zonos"
if zonos_path not in sys.path:
    sys.path.insert(0, zonos_path)

try:
    from zonos.model import Zonos
    from zonos.conditioning import make_cond_dict
    from zonos.utils import DEFAULT_DEVICE
    ZONOS_AVAILABLE = True
    print("âœ… Zonos ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    print(f"âŒ Zonos ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
    ZONOS_AVAILABLE = False


class ZonosTTSService:
    def __init__(self):
        self.model_path = "/home/hsc0125/Hing_tts/models/Zonos"
        self.audio_samples_path = "/home/hsc0125/Hing_tts/models/audio_data"
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.model = None
        self.korean_voices = {}
        print(f"ğŸ™ï¸ ZONOS TTS ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì¤‘... ë””ë°”ì´ìŠ¤: {self.device}")
        self._initialize_model()
        self._load_korean_voices()
    
    def _initialize_model(self):
        """ZONOS TTS ëª¨ë¸ ì´ˆê¸°í™”"""
        if not ZONOS_AVAILABLE:
            print("âš ï¸ Zonos ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë”ë¯¸ ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
            self.model = "dummy_zonos_model"
            return
            
        try:
            print(f"ğŸ“ ZONOS TTS ëª¨ë¸ ë¡œë”©...")
            
            # Zonos ëª¨ë¸ ë¡œë“œ (Hugging Faceì—ì„œ ìë™ ë‹¤ìš´ë¡œë“œ)
            # transformer ëª¨ë¸ ì‚¬ìš© (hybridëŠ” ë” ë§ì€ ë¦¬ì†ŒìŠ¤ í•„ìš”)
            self.model = Zonos.from_pretrained("Zyphra/Zonos-v0.1-transformer", device=self.device)
            self.model.requires_grad_(False).eval()
            
            print("âœ… ZONOS TTS ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ ZONOS TTS ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            print("âš ï¸ ë”ë¯¸ ëª¨ë“œë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
            traceback.print_exc()
            self.model = "dummy_zonos_model"
    
    def _load_korean_voices(self):
        """í•œêµ­ì–´ ìŒì„± ìƒ˜í”Œë“¤ì„ ë¡œë“œ"""
        try:
            audio_data_path = Path(self.audio_samples_path)
            print(f"ğŸ” ì˜¤ë””ì˜¤ ê²½ë¡œ í™•ì¸: {audio_data_path}")
            
            if not audio_data_path.exists():
                print(f"âš ï¸ ì˜¤ë””ì˜¤ ìƒ˜í”Œ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.audio_samples_path}")
                audio_data_path.mkdir(parents=True, exist_ok=True)
                print("ğŸ“ ì˜¤ë””ì˜¤ í´ë” ìƒì„±ë¨")
                return
            
            # ëª¨ë“  ì˜¤ë””ì˜¤ íŒŒì¼ í™•ì¸ (.wav, .mp3 ë“±)
            audio_files = []
            for ext in ['*.wav', '*.mp3', '*.flac', '*.ogg']:
                audio_files.extend(list(audio_data_path.glob(ext)))
            
            print(f"ğŸ” ë°œê²¬ëœ ì˜¤ë””ì˜¤ íŒŒì¼: {len(audio_files)}ê°œ")
            
            if not audio_files:
                print("âš ï¸ ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ìŒì„±ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
                return
            
            korean_speaker_names = ["í•œêµ­ì—¬ì„±1", "í•œêµ­ì—¬ì„±2", "í•œêµ­ë‚¨ì„±1", "í•œêµ­ë‚¨ì„±2", "í•œêµ­ì—¬ì„±3"]
            
            for i, audio_file in enumerate(audio_files[:len(korean_speaker_names)]):
                speaker_name = korean_speaker_names[i]
                self.korean_voices[speaker_name] = str(audio_file)
                print(f"ğŸ¤ ZONOS í•œêµ­ì–´ ìŒì„± ë“±ë¡: {speaker_name} -> {audio_file.name}")
            
            # ì²« ë²ˆì§¸ íŒŒì¼ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
            if audio_files:
                self.korean_voices["default"] = str(audio_files[0])
                print(f"âœ… ZONOS ê¸°ë³¸ ìŒì„± ì„¤ì •: {audio_files[0].name}")
                
        except Exception as e:
            print(f"âŒ ZONOS í•œêµ­ì–´ ìŒì„± ìƒ˜í”Œ ë¡œë“œ ì‹¤íŒ¨: {e}")
            traceback.print_exc()
    
    def list_korean_voices(self) -> List[str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ í•œêµ­ì–´ ìŒì„± ëª©ë¡ ë°˜í™˜"""
        return list(self.korean_voices.keys())
    
    def generate_speech(self, text: str, speaker_names: List[str] = None, cfg_scale: float = 2.0) -> str:
        """
        ZONOS TTSë¡œ í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜
        """
        if not self.model:
            raise Exception("ZONOS TTS ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
        
        # ì„ì‹œ ì¶œë ¥ íŒŒì¼ ìƒì„±
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_file:
            output_path = tmp_file.name
        
        try:
            print(f"ğŸ¬ ZONOS TTS ìŒì„± ìƒì„± ì‹œì‘: {text[:50]}...")
            
            if self.model == "dummy_zonos_model":
                # ë”ë¯¸ êµ¬í˜„: ì‚¬ì¸íŒŒ ì˜¤ë””ì˜¤ ìƒì„±
                sample_rate = 44100  # ZonosëŠ” 44kHz ì¶œë ¥
                duration = min(len(text) * 0.1, 10.0)
                t = np.linspace(0, duration, int(sample_rate * duration))
                frequency = 440
                audio_data = 0.3 * np.sin(2 * np.pi * frequency * t)
                sf.write(output_path, audio_data, sample_rate)
                print(f"ğŸ’¾ ZONOS TTS ë”ë¯¸ ìŒì„± íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_path}")
                return output_path
            
            # ì‹¤ì œ ZONOS TTS êµ¬í˜„
            # í•œêµ­ì–´ ìŒì„± ìƒ˜í”Œ ë¡œë“œ (speaker embedding ìƒì„±ìš©)
            speaker_embedding = None
            if self.korean_voices:
                try:
                    # ì²« ë²ˆì§¸ í•œêµ­ì–´ ìŒì„± ìƒ˜í”Œì„ speaker embeddingìœ¼ë¡œ ì‚¬ìš©
                    if "default" in self.korean_voices:
                        voice_path = self.korean_voices["default"]
                    else:
                        voice_path = list(self.korean_voices.values())[0]
                    
                    print(f"ğŸ¤ í•œêµ­ì–´ ìŒì„± ìƒ˜í”Œ ë¡œë“œ: {voice_path}")
                    wav, sr = torchaudio.load(voice_path)
                    speaker_embedding = self.model.make_speaker_embedding(wav, sr)
                    print("âœ… Speaker embedding ìƒì„± ì™„ë£Œ")
                except Exception as e:
                    print(f"âš ï¸ Speaker embedding ìƒì„± ì‹¤íŒ¨: {e}")
            
            # Conditioning dictionary ìƒì„±
            # ZonosëŠ” "ko" ëŒ€ì‹  "en-us"ë¥¼ ì‚¬ìš© (í•œêµ­ì–´ ì§ì ‘ ì§€ì› ì•ˆë¨, ì˜ì–´ë¡œ ëŒ€ì²´)
            cond_dict = make_cond_dict(
                text=text,
                language="en-us",  # ì˜ì–´ë¡œ ì„¤ì • (í•œêµ­ì–´ ë¯¸ì§€ì›)
                speaker=speaker_embedding,
                # ìì—°ìŠ¤ëŸ¬ìš´ ê°ì •
                emotion=[0.2, 0.05, 0.05, 0.05, 0.05, 0.05, 0.3, 0.25],  
                fmax=22050.0,  # Voice cloningì— ê¶Œì¥ë˜ëŠ” ê°’
                pitch_std=25.0,  # ì ë‹¹í•œ pitch variation
                speaking_rate=12.0,  # ì ë‹¹í•œ ì†ë„
                device=self.device
            )
            
            # Conditioning ì¤€ë¹„
            conditioning = self.model.prepare_conditioning(cond_dict)
            
            # ìŒì„± ìƒì„±
            print("ğŸµ ZONOSë¡œ ìŒì„± ìƒì„± ì¤‘...")
            with torch.inference_mode():
                codes = self.model.generate(
                    conditioning,
                    cfg_scale=cfg_scale,
                    max_new_tokens=int(len(text) * 8),  # í…ìŠ¤íŠ¸ ê¸¸ì´ì— ë¹„ë¡€
                    progress_bar=True,
                    disable_torch_compile=True  # C++ ì»´íŒŒì¼ëŸ¬ ë¬¸ì œ ë°©ì§€
                )
            
            # ì˜¤ë””ì˜¤ ë””ì½”ë”©
            print("ğŸ”„ ì˜¤ë””ì˜¤ ë””ì½”ë”© ì¤‘...")
            wavs = self.model.autoencoder.decode(codes).cpu()
            
            # WAV íŒŒì¼ë¡œ ì €ì¥ (ZonosëŠ” 44kHzë¡œ ì¶œë ¥)
            torchaudio.save(output_path, wavs[0], self.model.autoencoder.sampling_rate)
            
            print(f"ğŸ’¾ ZONOS TTS ìŒì„± íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_path}")
            return output_path
            
        except Exception as e:
            print(f"âŒ ZONOS TTS ìŒì„± ìƒì„± ì‹¤íŒ¨: {e}")
            traceback.print_exc()
            if os.path.exists(output_path):
                os.unlink(output_path)
            raise e